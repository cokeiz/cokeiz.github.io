<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.23.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="利用鸢尾花的实例，了解了KNN算法的应用">
<meta property="og:type" content="article">
<meta property="og:title" content="KNN算法">
<meta property="og:url" content="http://example.com/2025/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="Coke&#39;s Blog">
<meta property="og:description" content="利用鸢尾花的实例，了解了KNN算法的应用">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/images/16.png">
<meta property="article:published_time" content="2025-05-01T10:28:00.000Z">
<meta property="article:modified_time" content="2025-05-18T10:28:50.522Z">
<meta property="article:author" content="cokeiz">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="sklearn">
<meta property="article:tag" content="KNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2025/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/images/16.png">


<link rel="canonical" href="http://example.com/2025/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2025/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/","path":"2025/05/01/机器学习/KNN算法/","title":"KNN算法"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>KNN算法 | Coke's Blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Coke's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">人生苦短，我用python</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#KNN%E7%AE%97%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">KNN算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B"><span class="nav-number">1.1.</span> <span class="nav-text">KNN算法简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3"><span class="nav-number">1.1.1.</span> <span class="nav-text">KNN算法思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K%E5%80%BC%E7%9A%84%E9%80%89%E6%8B%A9"><span class="nav-number">1.1.2.</span> <span class="nav-text">K值的选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN%E7%9A%84%E5%BA%94%E7%94%A8%E6%96%B9%E5%BC%8F"><span class="nav-number">1.1.3.</span> <span class="nav-text">KNN的应用方式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#API%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.2.</span> <span class="nav-text">API介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BBAPI"><span class="nav-number">1.2.1.</span> <span class="nav-text">分类API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92API"><span class="nav-number">1.2.2.</span> <span class="nav-text">回归API</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.</span> <span class="nav-text">距离度量方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">1.4.</span> <span class="nav-text">特征预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%9B%E8%A1%8C%E5%BD%92%E4%B8%80%E5%8C%96%E3%80%81%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-number">1.4.1.</span> <span class="nav-text">为什么进行归一化、标准化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-number">1.4.2.</span> <span class="nav-text">归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-number">1.4.3.</span> <span class="nav-text">标准化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8KNN%E7%AE%97%E6%B3%95%E8%BF%9B%E8%A1%8C%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB"><span class="nav-number">1.4.4.</span> <span class="nav-text">利用KNN算法进行鸢尾花分类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">1.5.</span> <span class="nav-text">超参数选择的方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">1.5.1.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="nav-number">1.5.2.</span> <span class="nav-text">网格搜索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8KNN%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="nav-number">1.5.3.</span> <span class="nav-text">利用KNN算法实现手写数字识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.5.4.</span> <span class="nav-text">数据介绍</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%83%E4%B9%A0"><span class="nav-number">1.6.</span> <span class="nav-text">练习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%B4%E6%98%8E%E5%B8%B8%E8%A7%81%E7%9A%84%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E6%96%B9%E6%B3%95"><span class="nav-number">1.7.</span> <span class="nav-text">说明常见的距离度量方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%B4%E6%98%8E%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">1.8.</span> <span class="nav-text">说明特征预处理的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E5%86%99KNN%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB%E6%A1%88%E4%BE%8B"><span class="nav-number">1.9.</span> <span class="nav-text">编写KNN代码实现鸢尾花分类案例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E5%86%99KNN%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%8C%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2%EF%BC%89"><span class="nav-number">1.10.</span> <span class="nav-text">编写KNN代码实现手写数字识别（特征预处理，交叉验证网格搜索）</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">cokeiz</p>
  <div class="site-description" itemprop="description">用此来记录我的生活和学习笔记以及学习过程</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="cokeiz">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coke's Blog">
      <meta itemprop="description" content="用此来记录我的生活和学习笔记以及学习过程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="KNN算法 | Coke's Blog">
      <meta itemprop="description" content="利用鸢尾花的实例，了解了KNN算法的应用">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          KNN算法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-05-01 18:28:00" itemprop="dateCreated datePublished" datetime="2025-05-01T18:28:00+08:00">2025-05-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-18 18:28:50" itemprop="dateModified" datetime="2025-05-18T18:28:50+08:00">2025-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">利用鸢尾花的实例，了解了KNN算法的应用</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h1><h2 id="KNN算法简介"><a href="#KNN算法简介" class="headerlink" title="KNN算法简介"></a>KNN算法简介</h2><h3 id="KNN算法思想"><a href="#KNN算法思想" class="headerlink" title="KNN算法思想"></a>KNN算法思想</h3><p>K-近邻算法（K Nearest Neighbor，简称KNN）。比如：根据你的“邻居”来推断出你的类别</p>
<p>KNN算法思想：如果一个样本在特征空间中的 k 个最相似的样本中的大多数属于某一个类别，则该样本也属于这个类别 </p>
<p>思考：如何确定样本的相似性？</p>
<p><strong>样本相似性</strong>：样本都是属于一个任务数据集的。样本距离越近则越相似。</p>
<p>利用K近邻算法预测电影类型</p>
<h3 id="K值的选择"><a href="#K值的选择" class="headerlink" title="K值的选择"></a>K值的选择</h3><p>K值（邻居数量）是KNN的关键超参数，影响模型的偏差-方差权衡：</p>
<p>K值选择	               影响	          可能出现的问题<br>K太小（如K&#x3D;1）	模型复杂，对噪声敏感	容易过拟合（高方差）<br>K太大（如K&#x3D;100）	模型简单，边界平滑	可能欠拟合（高偏差）<br>适中K值（通过交叉验证选择）	平衡偏差和方差	需实验调优<br>如何选择K？</p>
<p>使用交叉验证（如GridSearchCV）测试不同K值。</p>
<p>观察验证集准确率，选择表现最好的K。</p>
<h3 id="KNN的应用方式"><a href="#KNN的应用方式" class="headerlink" title="KNN的应用方式"></a>KNN的应用方式</h3><ul>
<li><p>解决问题：分类问题、回归问题</p>
</li>
<li><p>算法思想：若一个样本在特征空间中的 k 个最相似的样本大多数属于某一个类别，则该样本也属于这个类别</p>
</li>
<li><p>相似性：欧氏距离</p>
</li>
<li><p>分类问题的处理流程：</p>
</li>
</ul>
<p>1.计算未知样本到每一个训练样本的距离</p>
<p>2.将训练样本根据距离大小升序排列</p>
<p>3.取出距离最近的 K 个训练样本</p>
<p>4.进行多数表决，统计 K 个样本中哪个类别的样本个数最多</p>
<p>5.将未知的样本归属到出现次数最多的类别</p>
<ul>
<li>回归问题的处理流程：</li>
</ul>
<p>1.计算未知样本到每一个训练样本的距离</p>
<p>2.将训练样本根据距离大小升序排列</p>
<p>3.取出距离最近的 K 个训练样本</p>
<p>4.把这个 K 个样本的目标值计算其平均值</p>
<p>5.作为将未知的样本预测的值</p>
<h2 id="API介绍"><a href="#API介绍" class="headerlink" title="API介绍"></a>API介绍</h2><h3 id="分类API"><a href="#分类API" class="headerlink" title="分类API"></a>分类API</h3><p>KNN分类API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier(n_neighbors=<span class="number">5</span>) </span><br></pre></td></tr></table></figure>

<p>​     n_neighbors：int,可选（默认&#x3D; 5），k_neighbors查询默认使用的邻居数</p>
<h3 id="回归API"><a href="#回归API" class="headerlink" title="回归API"></a>回归API</h3><p>KNN分类API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsRegressor(n_neighbors=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.工具包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier,KNeighborsRegressor</span><br><span class="line"><span class="comment"># from sklearn.neighbors import KNeighborsRegressor</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据(特征工程)</span></span><br><span class="line"><span class="comment"># 分类</span></span><br><span class="line"><span class="comment"># x = [[0,2,3],[1,3,4],[3,5,6],[4,7,8],[2,3,4]]</span></span><br><span class="line"><span class="comment"># y = [0,0,1,1,0]</span></span><br><span class="line">x = [[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]]</span><br><span class="line">y = [<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.实例化</span></span><br><span class="line"><span class="comment"># model =KNeighborsClassifier(n_neighbors=3)</span></span><br><span class="line">model =KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.训练</span></span><br><span class="line">model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.预测</span></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">4</span>,<span class="number">4</span>,<span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>





<h2 id="距离度量方法"><a href="#距离度量方法" class="headerlink" title="距离度量方法"></a>距离度量方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 欧式距离（Euclidean Distance）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclidean_distance</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算欧式距离（直线距离）</span></span><br><span class="line"><span class="string">    公式: sqrt( sum( (x_i - y_i)^2 ) )</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>((x - y) ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 曼哈顿距离（Manhattan Distance）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">manhattan_distance</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算曼哈顿距离（城市街区距离）</span></span><br><span class="line"><span class="string">    公式: sum( |x_i - y_i| )</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(x - y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 切比雪夫距离（Chebyshev Distance）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chebyshev_distance</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算切比雪夫距离（最大坐标差）</span></span><br><span class="line"><span class="string">    公式: max( |x_i - y_i| )</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">max</span>(np.<span class="built_in">abs</span>(x - y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 闵氏距离（Minkowski Distance）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">minkowski_distance</span>(<span class="params">x, y, p</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算闵氏距离（欧式和曼哈顿的泛化）</span></span><br><span class="line"><span class="string">    公式: ( sum( |x_i - y_i|^p ) )^(1/p)</span></span><br><span class="line"><span class="string">    当 p=1: 曼哈顿距离；p=2: 欧式距离；p→∞: 切比雪夫距离</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(x - y) ** p) ** (<span class="number">1</span>/p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------- 示例使用 ----------</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 定义两个向量（支持任意维度）</span></span><br><span class="line">    x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">    y = np.array([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算并打印各距离</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;欧式距离: <span class="subst">&#123;euclidean_distance(x, y):<span class="number">.3</span>f&#125;</span>&quot;</span>)          <span class="comment"># 输出: 5.196</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;曼哈顿距离: <span class="subst">&#123;manhattan_distance(x, y)&#125;</span>&quot;</span>)            <span class="comment"># 输出: 9</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;切比雪夫距离: <span class="subst">&#123;chebyshev_distance(x, y)&#125;</span>&quot;</span>)          <span class="comment"># 输出: 3</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;闵氏距离 (p=3): <span class="subst">&#123;minkowski_distance(x, y, <span class="number">3</span>):<span class="number">.3</span>f&#125;</span>&quot;</span>) <span class="comment"># 输出: 4.326</span></span><br></pre></td></tr></table></figure>
<p>•闵可夫斯基距离 Minkowski Distance 闵氏距离，不是一种新的距离的度量方式。而是距离的组合 是对多个距离度量公式的概括性的表述</p>
<h2 id="特征预处理"><a href="#特征预处理" class="headerlink" title="特征预处理"></a>特征预处理</h2><h3 id="为什么进行归一化、标准化"><a href="#为什么进行归一化、标准化" class="headerlink" title="为什么进行归一化、标准化"></a>为什么进行归一化、标准化</h3><p>特征的<strong>单位或者大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级</strong>，<strong>容易影响（支配）目标结果</strong>，使得一些模型（算法）无法学习到其它的特征。</p>
<h3 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h3><p>通过对原始数据进行变换把数据映射到【mi,mx】(默认为[0,1])之间</p>
<p>数据归一化的API实现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.MinMaxScaler (feature_range=(0,1)… )</span><br></pre></td></tr></table></figure>

<p> feature_range 缩放区间</p>
<ul>
<li>调用 fit_transform(X) 将特征进行归一化缩放</li>
</ul>
<p>归一化受到最大值与最小值的影响，这种方法容易受到异常数据的影响, 鲁棒性较差，适合传统精确小数据场景</p>
<h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>通过对原始数据进行标准化，转换为均值为0标准差为1的标准正态分布的数据</p>
<ul>
<li>mean 为特征的平均值</li>
<li>σ 为特征的标准差</li>
</ul>
<p>数据标准化的API实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing. StandardScaler()</span><br></pre></td></tr></table></figure>

<p>调用 fit_transform(X) 将特征进行归一化缩放</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入工具包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler,StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据(只有特征)</span></span><br><span class="line">x = [[<span class="number">90</span>, <span class="number">2</span>, <span class="number">10</span>, <span class="number">40</span>], [<span class="number">60</span>, <span class="number">4</span>, <span class="number">15</span>, <span class="number">45</span>], [<span class="number">75</span>, <span class="number">3</span>, <span class="number">13</span>, <span class="number">46</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.实例化(归一化,标准化)</span></span><br><span class="line"><span class="comment"># process =MinMaxScaler()</span></span><br><span class="line">process =StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.fit_transform 处理1</span></span><br><span class="line">data =process.fit_transform(x)</span><br><span class="line"><span class="comment"># print(data)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(process.mean_)</span><br><span class="line"><span class="built_in">print</span>(process.var_)</span><br></pre></td></tr></table></figure>



<p>对于标准化来说，如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大</p>
<h3 id="利用KNN算法进行鸢尾花分类"><a href="#利用KNN算法进行鸢尾花分类" class="headerlink" title="利用KNN算法进行鸢尾花分类"></a>利用KNN算法进行鸢尾花分类</h3><p>鸢尾花Iris Dataset数据集是机器学习领域经典数据集，鸢尾花数据集包含了150条鸢尾花信息，每50条取自三个鸢尾花中之一：Versicolour、Setosa和Virginica</p>
<p>每个花的特征用如下属性描述：</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0.导入工具包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.加载数据集</span></span><br><span class="line">iris_data = load_iris()</span><br><span class="line"><span class="comment"># print(iris_data)</span></span><br><span class="line"><span class="comment"># print(iris_data.target)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据展示</span></span><br><span class="line">iris_df = pd.DataFrame(iris_data[<span class="string">&#x27;data&#x27;</span>], columns=iris_data.feature_names)</span><br><span class="line">iris_df[<span class="string">&#x27;label&#x27;</span>] = iris_data.target</span><br><span class="line"><span class="comment"># print(iris_data.feature_names)</span></span><br><span class="line"><span class="comment"># sns.lmplot(x=&#x27;sepal length (cm)&#x27;,y=&#x27;sepal width (cm)&#x27;,data = iris_df,hue=&#x27;label&#x27;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.特征工程(预处理-标准化)</span></span><br><span class="line"><span class="comment"># 3.1 数据集划分</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=<span class="number">0.3</span>, random_state=<span class="number">22</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(iris_data.data))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(x_train))</span><br><span class="line"><span class="comment"># 3.2 标准化</span></span><br><span class="line">process = StandardScaler()</span><br><span class="line">x_train = process.fit_transform(x_train)</span><br><span class="line">x_test = process.transform(x_test)</span><br><span class="line"><span class="comment"># 4.模型训练</span></span><br><span class="line"><span class="comment"># 4.1 实例化</span></span><br><span class="line">model = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 4.2 调用fit法</span></span><br><span class="line">model.fit(x_train,y_train)</span><br><span class="line"><span class="comment"># 5.模型预测</span></span><br><span class="line">x = [[<span class="number">5.1</span>, <span class="number">3.5</span>, <span class="number">1.4</span>, <span class="number">0.2</span>]]</span><br><span class="line">x=process.transform(x)</span><br><span class="line">y_predict =model.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(model.predict_proba(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.模型评估(准确率)</span></span><br><span class="line"><span class="comment"># 6.1 使用预测结果</span></span><br><span class="line">acc =accuracy_score(y_test,y_predict)</span><br><span class="line"><span class="built_in">print</span>(acc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.2 直接计算</span></span><br><span class="line">acc = model.score(x_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(acc)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="超参数选择的方法"><a href="#超参数选择的方法" class="headerlink" title="超参数选择的方法"></a>超参数选择的方法</h2><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>交叉验证是一种数据集的分割方法，将训练集划分为 n 份，其中一份做验证集、其他n-1份做训练集集 </p>
<p><strong>交叉验证法原理</strong>：将数据集划分为 cv&#x3D;10 份：</p>
<p>1.第一次：把第一份数据做验证集，其他数据做训练</p>
<p>2.第二次：把第二份数据做验证集，其他数据做训练</p>
<p>3…. 以此类推，总共训练10次，评估10次。</p>
<p>4.使用训练集+验证集多次评估模型，取平均值做交叉验证为模型得分</p>
<p>5.若k&#x3D;5模型得分最好，再使用全部训练集(训练集+验证集) 对k&#x3D;5模型再训练一边，再使用测试集对k&#x3D;5模型做评估</p>
<h3 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h3><p>交叉验证网格搜索的API:</p>
<p>交叉验证网格搜索在鸢尾花分类中的应用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0.导入工具包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split,GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.加载数据</span></span><br><span class="line">data = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 数据集划分</span></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(data.data,data.target,test_size=<span class="number">0.2</span>,random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.特征预处理</span></span><br><span class="line">pre = StandardScaler()</span><br><span class="line">x_train=pre.fit_transform(x_train)</span><br><span class="line">x_test=pre.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.模型实例化+交叉验证+网格搜索</span></span><br><span class="line">model = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">paras_grid = &#123;<span class="string">&#x27;n_neighbors&#x27;</span>:[<span class="number">4</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>]&#125;</span><br><span class="line"><span class="comment"># estimator =GridSearchCV(estimator=model,param_grid=paras_grid,cv=4)</span></span><br><span class="line"><span class="comment"># estimator.fit(x_train,y_train)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(estimator.best_score_)</span></span><br><span class="line"><span class="comment"># print(estimator.best_estimator_)</span></span><br><span class="line"><span class="comment"># print(estimator.cv_results_)</span></span><br><span class="line"></span><br><span class="line">model = KNeighborsClassifier(n_neighbors=<span class="number">7</span>)</span><br><span class="line">model.fit(x_train,y_train)</span><br><span class="line">x = [[<span class="number">5.1</span>, <span class="number">3.5</span>, <span class="number">1.4</span>, <span class="number">0.2</span>]]</span><br><span class="line">x=pre.transform(x)</span><br><span class="line">y_prdict=model.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy_score(y_test,y_prdict))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h3 id="利用KNN算法实现手写数字识别"><a href="#利用KNN算法实现手写数字识别" class="headerlink" title="利用KNN算法实现手写数字识别"></a>利用KNN算法实现手写数字识别</h3><p>MNIST手写数字识别 是计算机视觉领域中 “hello world”级别的数据集</p>
<ul>
<li>1999年发布，成为分类算法基准测试的基础</li>
<li>随着新的机器学习技术的出现，MNIST仍然是研究人员和学习者的可靠资源。</li>
</ul>
<p>本次案例中，我们的目标是从数万个手写图像的数据集中正确识别数字。</p>
<h3 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h3><p>数据文件 train.csv 和 test.csv 包含从 0 到 9 的手绘数字的灰度图像。</p>
<ul>
<li><p>每个图像高 28 像素，宽28 像素，共784个像素。</p>
</li>
<li><p>每个像素取值范围[0,255]，取值越大意味着该像素颜色越深</p>
</li>
<li><p>训练数据集（train.csv）共785列。第一列为 “标签”，为该图片对应的手写数字。其余784列为该图像的像素值</p>
</li>
<li><p>训练集中的特征名称均有pixel前缀，后面的数字（[0,783])代表了像素的序号。</p>
</li>
</ul>
<p>像素组成图像如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">000</span> 001 002 003 ... 026 027</span><br><span class="line">028 029 030 031 ... 054 055</span><br><span class="line">056 057 058 059 ... 082 083</span><br><span class="line"> | | | | ...... | |</span><br><span class="line"><span class="number">728</span> <span class="number">729</span> <span class="number">730</span> <span class="number">731</span> ... <span class="number">754</span> <span class="number">755</span></span><br><span class="line"><span class="number">756</span> <span class="number">757</span> <span class="number">758</span> <span class="number">759</span> ... <span class="number">782</span> <span class="number">783</span></span><br></pre></td></tr></table></figure>

<p>数据集示例如下:<br><img src="images/16.png" /></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><h2 id="说明常见的距离度量方法"><a href="#说明常见的距离度量方法" class="headerlink" title="说明常见的距离度量方法"></a>说明常见的距离度量方法</h2><ul>
<li><p>欧式距离法</p>
<ul>
<li>对应维度数据相减平方求和后开方</li>
</ul>
</li>
<li><p>曼哈顿距离法</p>
<ul>
<li>对应维度数据相减求绝对值求和</li>
</ul>
</li>
<li><p>切比雪夫距离</p>
<ul>
<li>对应维度数据相减求绝对值求最大</li>
</ul>
</li>
<li><p>闵可夫斯基距离</p>
<ul>
<li>上述距离的综合</li>
<li>对应维度数据相减p次方求和后开p次方</li>
</ul>
</li>
</ul>
<h2 id="说明特征预处理的方法"><a href="#说明特征预处理的方法" class="headerlink" title="说明特征预处理的方法"></a>说明特征预处理的方法</h2><ul>
<li><p>归一化：</p>
<ul>
<li>对原始数据进行变换到【mi,mx】(默认为[0,1])之间</li>
<li>受异常值影响，一般不常用</li>
</ul>
</li>
<li><p>标准化：</p>
<ul>
<li>将原始数据转换为均值为0标准差为1的标准正态分布的数据</li>
<li>不易受异常值影响，常用</li>
</ul>
</li>
</ul>
<h2 id="编写KNN代码实现鸢尾花分类案例"><a href="#编写KNN代码实现鸢尾花分类案例" class="headerlink" title="编写KNN代码实现鸢尾花分类案例"></a>编写KNN代码实现鸢尾花分类案例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入工具包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">iris_data = load_iris()</span><br><span class="line"><span class="comment"># print(iris_data)</span></span><br><span class="line"><span class="built_in">print</span>(iris_data.feature_names)</span><br><span class="line">iris_df = pd.DataFrame(iris_data[<span class="string">&#x27;data&#x27;</span>], columns=iris_data.feature_names)</span><br><span class="line">iris_df[<span class="string">&#x27;label&#x27;</span>] = iris_data.target</span><br><span class="line">sns.lmplot(x=<span class="string">&#x27;sepal length (cm)&#x27;</span>, y=<span class="string">&#x27;sepal width (cm)&#x27;</span>, data=iris_df, hue=<span class="string">&#x27;label&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 数据集划分</span></span><br><span class="line">x_train, x_test, y_train, y_text = train_test_split(iris_data.data, iris_data.target, test_size=<span class="number">0.3</span>, random_state=<span class="number">22</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(iris_data.data))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(x_train))</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">process = StandardScaler()</span><br><span class="line">x_train = process.fit_transform(x_train)</span><br><span class="line">x_test = process.transform(x_test)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line">x = [[<span class="number">5.1</span>, <span class="number">3.5</span>, <span class="number">1.4</span>, <span class="number">0.2</span>]]</span><br><span class="line">x = process.transform(x)</span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_predict = model.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(model.predict_proba(x))</span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">acc = accuracy_score(y_text, y_predict)</span><br><span class="line"><span class="built_in">print</span>(acc)</span><br></pre></td></tr></table></figure>



<h2 id="编写KNN代码实现手写数字识别（特征预处理，交叉验证网格搜索）"><a href="#编写KNN代码实现手写数字识别（特征预处理，交叉验证网格搜索）" class="headerlink" title="编写KNN代码实现手写数字识别（特征预处理，交叉验证网格搜索）"></a>编写KNN代码实现手写数字识别（特征预处理，交叉验证网格搜索）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入工具包</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span>  MinMaxScaler</span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;手写数字识别.csv&#x27;</span>)</span><br><span class="line">x = data.iloc[:, <span class="number">1</span>:]</span><br><span class="line">y = data.iloc[:, <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 特征归一化【注意】</span></span><br><span class="line">transform = MinMaxScaler()</span><br><span class="line">x = transform.fit_transform(x)</span><br><span class="line"><span class="comment"># x = x / 255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>, stratify=y, random_state=<span class="number">22</span>)</span><br><span class="line"><span class="comment"># 模型实例化</span></span><br><span class="line">model = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 网格搜索交叉验证</span></span><br><span class="line">param_grid = &#123;<span class="string">&#x27;n_neighbors&#x27;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]&#125;</span><br><span class="line">model = GridSearchCV(estimator=model, param_grid=param_grid, cv=<span class="number">4</span>)</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(model.best_estimator_)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">img = plt.imread(<span class="string">&#x27;demo.png&#x27;</span>)</span><br><span class="line">img=img.reshape(<span class="number">1</span>,-<span class="number">1</span>) / <span class="number">255.</span></span><br><span class="line"><span class="built_in">print</span>(model.predict(img))</span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="built_in">print</span>(model.score(x_test, y_test))</span><br></pre></td></tr></table></figure>
<p><strong>生成结果有误，应该是图片原因</strong></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/sklearn/" rel="tag"># sklearn</a>
              <a href="/tags/KNN/" rel="tag"># KNN</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/04/30/Python%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6%201e13311af3f58073ab5be03d64c886f5/%E9%97%AD%E5%8C%85%E8%A3%85%E9%A5%B0%E5%99%A8%201e63311af3f580e081d4e293f50d790d/" rel="prev" title="闭包装饰器">
                  <i class="fa fa-angle-left"></i> 闭包装饰器
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/05/01/Python%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6%201e13311af3f58073ab5be03d64c886f5/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%201e63311af3f580cfb0d8d03a5987b2e4/" rel="next" title="网络编程">
                  网络编程 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">cokeiz</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
